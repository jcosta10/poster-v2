<!DOCTYPE html>
<html>

<head>
    <link rel="icon" href="icon.png">
    <title> (Re)thinkg Gender Bias</title>
    <link rel="icon" href="imagens/circle.png" type="image/png"
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&family=Montserrat:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600&family=Open+Sans:wght@500&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="style.css">
  
</head>
<body>
    <script src="javascript.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <h2><span class="word">(Re)thinking </span> Gender Bias in facial recognition</h2>
    <div id="content">
        <div class="right" id="right">
            <div class="content-legend">
            <p class="keyword"><span class="dot"></span> Gender Bias</span></p>
            <p class="keyword"><span class="dot"></span> Bias</span></p>
            <p class="keyword"><span class="dot"></span> Hitorical Bias</span></p>
            <p class="keyword"><span class="dot"></span> World Bias</span></p>
            <p class="keyword"><span class="dot"></span> Social Bias</span></p>
            <p class="keyword"><span class="dot"></span> Algorithmic Bias</span></p>
            <p class="keyword"><span class="dot"></span> Machine learning</span></p>
            <p class="keyword"><span class="dot"></span> Artificial intelligence</span></p>
            <p class="keyword"><span class="dot"></span> Discriminatory systems</span></p>
            <p class="keyword"><span class="dot"></span> De-bias the systems</span></p>
            <p class="keyword"><span class="dot"></span> Past social</span></p>
            <p class="keyword"><span class="dot"></span> Impact on society</span></p>
            <p class="keyword"><span class="dot"></span> Specific bias</span></p>
            <p class="keyword"><span class="dot"></span> Past biases</span></p>
            <p class="keyword"><span class="dot"></span> Gender inequality</span></p>
            <p class="keyword"><span class="dot"></span> Gender discrimination</span></p>
            <p class="keyword"><span class="dot"></span> Facial Recognition</span></p>
            <p class="keyword"><span class="dot"></span> Human Bias</span></p>
            <p class="keyword"><span class="dot"></span> Learning Bias</span></p>
            <p class="keyword"><span class="dot"></span> Traning data</span></p>
            <p class="keyword"><span class="dot"></span> Datasets bias</span></p>
            <p class="keyword"><span class="dot"></span> Implicit bias</span></p>
            <p class="keyword"><span class="dot"></span> Explicit bias</span></p>
            <p class="keyword"><span class="dot"></span> Labeling bias</span></p>
            <p class="keyword"><span class="dot"></span> Unique Anomaly</span></p>
            <p class="keyword"><span class="dot"></span> Black Box Effect</span></p>
            <p class="keyword"><span class="dot"></span> Algorithm anomaly</span></p>
            </div>
        </div>
        <div class="left">
            <p>
                <span class="title">// Summary</span><br>
                <span class="keyword"><span class="dot"></span> Machine learning</span>
                (ML) is a type of
                <span class="keyword"><span class="dot"></span>  artificial intelligence</span> 
                technology that relies on vast datasets for training. ML is currently being use in various systems for automated decision making.
                <a class="legend" href="https://www.raspberrypi.org/blog/gender-bias-in-ai-machine-learning-biased-data/">[1]</a>
                The limitations of AI are generally perceived today thanks to the discourse on
                <span class="keyword"><span class="dot"></span> bias</span> 
                - the amplification of gender, race, ability, and class discrimination by algorithms. 
                <span class="keyword"><span class="dot"></span>  Historical bias</span>
                (or 
                <span class="keyword"><span class="dot"></span> world bias</span>) is already apparent in society before technological intervention. Nonetheless, the naturalization of such 
                <span class="keyword"><span class="dot"></span> bias</span>
                , that is the silent integration of 
                <span class="keyword"><span class="dot"></span> inequality</span>  into an apparently neutral technology is by itself harmful. Paraphrasing Michelle Alexander, Ruha Benjamin has called it the New Jim Code: the employment of new technologies that reflect and reproduce existing inequalities but that are promoted and perceived as more objective or progressive than the 
                <span class="keyword"><span class="dot"></span>  discriminatory systems</span> 
                of a previous era.  
                <a class="legend" href="https://nooscope.ai/">[2]</a>
                A historical data set of successful applicants will essentially be a male-dominated data set, To give women equal opportunity in these areas, we need to look at how to 
                <span class="keyword"><span class="dot"></span> de-bias the systems</span>.
                <a class="legend" href="https://www.euronews.com/next/2022/03/08/gender-bias-in-recruitment-how-ai-hiring-tools-are-hindering-women-s-careers">[3]</a>
            <p>
                <span class="title">// Purpose</span><br>
                Promote critical reflection on the impact of 
                <span class="keyword"><span class="dot"></span> gender bias</span>
                and how the development of
                <span class="keyword"><span class="dot"></span>
                artificial intelligence</span> systems based on
                <span class="keyword"><span class="dot"></span> past social</span>
                and cultural prejudices affects the society today. By increasing awareness of this issue, the aim is to encourage reconsideration of more ethical and inclusive technologies.
            </p>
            <p>
                <span class="title">// Objectives</span><br>
                - Deconstruct 
                <span class="keyword"><span class="dot"></span> gender bias</span>
                by analyzing how social context influences
                <span class="keyword"><span class="dot"></span> machine learning</span> and its
                <span class="keyword"><span class="dot"></span> impact on society</span>. <br>

                - Identify and assign projects to 
                <span class="keyword"><span class="dot"></span> specific bias</span>
                categories (social, algorithmic and gender). <br>

                - Develop an interface in order to promote discussion and expose the problem of how machines are being built based on
                <span class="keyword"><span class="dot"></span> past biases</span>
                and how they are promoting discrimination on gender.
            </p>
            <p>
                <span class="title">// Methodology</span><br>
                - Define, group and relate relevant content content such as projects, articles, and quotes that highlight the issue of 
                <span class="keyword"><span class="dot"></span> gender inequality</span>
                in
                <span class="keyword"><span class="dot"></span> facial recognition</span>.
                <br>

                - Develop an interface that can create a distinction between genders in 
                <span class="keyword"><span class="dot"></span> facial recognition</span>
                systems. This capability will allow users to confront the biases that often exist in these algorithms.<br>

                - In addition, within the same interface, create a diagram that illustrates the different layers connecting 
                <span class="keyword"><span class="dot"></span> social bias</span>
                and 
                <span class="keyword"><span class="dot"></span> algorithmic bias</span>
                , ultimately resulting in
                <span class="keyword"><span class="dot"></span> gender discrimination</span>.
            </p>
            <p>
                <span class="title">// Expected Outcome</span><br>
                This project aims to facilitate reflection on how algorithms are built with 
                <span class="keyword"><span class="dot"></span> past biases</span>
                and promote change towards building less gender-biased systems. By doing so, I hope to contribute to creating a more equal society. 
            </p>
            <p>
                <a href="https://www.raspberrypi.org/blog/gender-bias-in-ai-machine-learning-biased-data/"class="legend">[1] Sue Sentande (2022). Bias in the machine: How can we address gender bias in AI?. Raspberry Pi Foundation. Consultado em Março 2022.</a><br>
                <a class="legend" href="https://nooscope.ai/">[2] Vladan Joler and Matteo Pasquinelli (2020). The Nooscope Manifested: AI as Instrument of Knowledge Extractivism. Nooscope.ai. Consultado em Março 2022.</a><br>
                <a class="legend" href="https://www.euronews.com/next/2022/03/08/gender-bias-in-recruitment-how-ai-hiring-tools-are-hindering-women-s-careers">[3] Natalie Huet (2022). Gender bias in recruitment: How AI hiring tools are hindering women’s careers. Euronew.next. Consultado em Março 2022.</a>
            <p class="title">// MDC // PROJECT II // Joana Costa</p>
        </div>
    </div>


<script>
    function typeWriter(elemento){
        const textArray = elemento.innerHTML.split('');
        elemento.innerHTML = '';
        textArray.forEach((letra, i) => {
            setTimeout(function(){
                elemento.innerHTML += letra;
            }, 100 * i)
        })
    }

    const title = document.querySelector('.word');
    typeWriter(title);
</script> 

<script type="text/javascript">
    var $el = $(".right");
    function anim() {
    var st = $el.scrollTop();
    var sb = $el.prop("scrollHeight")-$el.innerHeight();
    $el.animate({scrollTop: st<sb/2 ? sb : 0}, 1000, anim);
    }
    
    function stop(){
      $el.stop();
    }
    anim();
    $el.hover(stop, anim);
</script>

</body>
</html>